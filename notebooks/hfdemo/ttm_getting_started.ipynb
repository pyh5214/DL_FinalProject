{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pyh5214/DL_FinalProject/blob/main/notebooks/hfdemo/ttm_getting_started.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7478e0e2-b7af-4fd4-b44e-ca58e0c31b71",
      "metadata": {
        "id": "7478e0e2-b7af-4fd4-b44e-ca58e0c31b71"
      },
      "source": [
        "# Getting started with TinyTimeMixer (TTM)\n",
        "\n",
        "This notebooke demonstrates the usage of a pre-trained `TinyTimeMixer` model for several multivariate time series forecasting tasks. For details related to model architecture, refer to the [TTM paper](https://arxiv.org/pdf/2401.03955.pdf).\n",
        "\n",
        "In this example, we will use a pre-trained TTM-512-96 model. That means the TTM model can take an input of 512 time points (`context_length`), and can forecast upto 96 time points (`forecast_length`) in the future. We will use the pre-trained TTM in two settings:\n",
        "1. **Zero-shot**: The pre-trained TTM will be directly used to evaluate on the `test` split of the target data. Note that the TTM was NOT pre-trained on the target data.\n",
        "2. **Few-shot**: The pre-trained TTM will be quickly fine-tuned on only 5% of the `train` split of the target data, and subsequently, evaluated on the `test` part of the target data.\n",
        "\n",
        "Note: Alternatively, this notebook can be modified to try any other TTM model from a suite of TTM models. For details, visit the [Hugging Face TTM Model Repository](https://huggingface.co/ibm-granite/granite-timeseries-ttm-r2).\n",
        "\n",
        "1. IBM Granite TTM-R1 pre-trained models can be found here: [Granite-TTM-R1 Model Card](https://huggingface.co/ibm-granite/granite-timeseries-ttm-r1)\n",
        "2. IBM Granite TTM-R2 pre-trained models can be found here: [Granite-TTM-R2 Model Card](https://huggingface.co/ibm-granite/granite-timeseries-ttm-r2)\n",
        "3. Research-use (non-commercial use only) TTM-R2 pre-trained models can be found here: [Research-Use-TTM-R2](https://huggingface.co/ibm-research/ttm-research-r2)\n",
        "\n",
        "### The get_model() utility\n",
        "TTM Model card offers a suite of models with varying `context_length` and `prediction_length` combinations.\n",
        "In this notebook, we will utilize the TSFM `get_model()` utility that automatically selects the right model based on the given input `context_length` and `prediction_length` (and some other optional arguments) abstracting away the internal complexity. See the usage examples below in the `zeroshot_eval()` and `fewshot_finetune_eval()` functions. For more details see the [docstring](https://github.com/ibm-granite/granite-tsfm/blob/main/tsfm_public/toolkit/get_model.py) of the function definition."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ab69d3f-a4e4-427a-8c8d-36c82b305855",
      "metadata": {
        "id": "3ab69d3f-a4e4-427a-8c8d-36c82b305855"
      },
      "source": [
        "## Install `tsfm`\n",
        "**[Optional for Local Run / Mandatory for Google Colab]**  \n",
        "Run the below cell to install `tsfm`. Skip if already installed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "12c23095-302a-4412-8fc9-a4143ca4249c",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12c23095-302a-4412-8fc9-a4143ca4249c",
        "outputId": "71749e39-2ebd-4dcf-caaf-52dac18e0e4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22 (from granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22)\n",
            "  Cloning https://github.com/ibm-granite/granite-tsfm.git (to revision v0.2.22) to /tmp/pip-install-89n_bbz2/granite-tsfm_a652c118f58f4a9eba4dca61beefd79d\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/ibm-granite/granite-tsfm.git /tmp/pip-install-89n_bbz2/granite-tsfm_a652c118f58f4a9eba4dca61beefd79d\n",
            "  Running command git checkout -q 216850d0cb073e31689049c1334f701fe11bc2c3\n",
            "  Resolved https://github.com/ibm-granite/granite-tsfm.git to commit 216850d0cb073e31689049c1334f701fe11bc2c3\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pandas>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (1.6.1)\n",
            "Requirement already satisfied: transformers>=4.38.0 in /usr/local/lib/python3.12/dist-packages (from transformers[torch]>=4.38.0->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (4.55.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (from granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (4.0.0)\n",
            "Requirement already satisfied: deprecated in /usr/local/lib/python3.12/dist-packages (from granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (1.2.18)\n",
            "Requirement already satisfied: urllib3<2,>=1.26.19 in /usr/local/lib/python3.12/dist-packages (from granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (1.26.20)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.12/dist-packages (from granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (1.26.4)\n",
            "Requirement already satisfied: jupyter in /usr/local/lib/python3.12/dist-packages (from granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (1.1.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (3.10.0)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.12/dist-packages (from granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (7.7.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (from granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (5.24.1)\n",
            "Requirement already satisfied: kaleido in /usr/local/lib/python3.12/dist-packages (from granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (1.0.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.12/dist-packages (from granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (2.19.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.2.0->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.2.0->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.2.0->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (2025.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers>=4.38.0->transformers[torch]>=4.38.0->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.38.0->transformers[torch]>=4.38.0->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (0.34.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.38.0->transformers[torch]>=4.38.0->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.38.0->transformers[torch]>=4.38.0->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.38.0->transformers[torch]>=4.38.0->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers>=4.38.0->transformers[torch]>=4.38.0->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.38.0->transformers[torch]>=4.38.0->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.38.0->transformers[torch]>=4.38.0->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.38.0->transformers[torch]>=4.38.0->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (4.67.1)\n",
            "Requirement already satisfied: torch>=2.1 in /usr/local/lib/python3.12/dist-packages (from transformers[torch]>=4.38.0->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (2.8.0+cu126)\n",
            "Requirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.12/dist-packages (from transformers[torch]>=4.38.0->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (1.10.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (2025.3.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.12/dist-packages (from deprecated->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (1.17.3)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.12/dist-packages (from ipywidgets->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (6.17.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.12/dist-packages (from ipywidgets->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (3.6.10)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (7.34.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (3.0.15)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.12/dist-packages (from jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (6.5.7)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.12/dist-packages (from jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (6.1.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.12/dist-packages (from jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (7.16.6)\n",
            "Requirement already satisfied: jupyterlab in /usr/local/lib/python3.12/dist-packages (from jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (4.4.6)\n",
            "Requirement already satisfied: choreographer>=1.0.5 in /usr/local/lib/python3.12/dist-packages (from kaleido->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (1.0.9)\n",
            "Requirement already satisfied: logistro>=1.0.8 in /usr/local/lib/python3.12/dist-packages (from kaleido->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (1.1.0)\n",
            "Requirement already satisfied: orjson>=3.10.15 in /usr/local/lib/python3.12/dist-packages (from kaleido->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (3.11.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (4.59.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (3.2.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (9.1.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (3.6.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (1.74.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (3.8.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.12/dist-packages (from tensorboard->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (5.29.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.12/dist-packages (from tensorboard->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (3.1.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.26.0->transformers[torch]>=4.38.0->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (5.9.5)\n",
            "Requirement already satisfied: simplejson>=3.19.3 in /usr/local/lib/python3.12/dist-packages (from choreographer>=1.0.5->kaleido->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (3.20.1)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (3.12.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.38.0->transformers[torch]>=4.38.0->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.38.0->transformers[torch]>=4.38.0->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (1.1.7)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (1.8.15)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (7.4.9)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (1.6.0)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (26.2.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (6.4.2)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (3.0.51)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (2.19.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.38.0->transformers[torch]>=4.38.0->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.38.0->transformers[torch]>=4.38.0->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.38.0->transformers[torch]>=4.38.0->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (2025.8.3)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->transformers[torch]>=4.38.0->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->transformers[torch]>=4.38.0->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->transformers[torch]>=4.38.0->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->transformers[torch]>=4.38.0->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->transformers[torch]>=4.38.0->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->transformers[torch]>=4.38.0->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->transformers[torch]>=4.38.0->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->transformers[torch]>=4.38.0->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->transformers[torch]>=4.38.0->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->transformers[torch]>=4.38.0->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->transformers[torch]>=4.38.0->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->transformers[torch]>=4.38.0->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->transformers[torch]>=4.38.0->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->transformers[torch]>=4.38.0->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->transformers[torch]>=4.38.0->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->transformers[torch]>=4.38.0->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->transformers[torch]>=4.38.0->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->transformers[torch]>=4.38.0->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (3.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (3.0.2)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.12/dist-packages (from notebook->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (25.1.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.12/dist-packages (from notebook->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (5.8.1)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.12/dist-packages (from notebook->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (5.10.4)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from notebook->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.12/dist-packages (from notebook->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.12/dist-packages (from notebook->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (0.22.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.12/dist-packages (from notebook->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (1.3.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (4.13.4)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.12/dist-packages (from bleach[css]!=5.0.0->nbconvert->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (3.1.3)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (1.5.1)\n",
            "Requirement already satisfied: async-lru>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (2.0.5)\n",
            "Requirement already satisfied: httpx<1,>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (0.28.1)\n",
            "Requirement already satisfied: jupyter-lsp>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (2.2.6)\n",
            "Requirement already satisfied: jupyter-server<3,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (2.16.0)\n",
            "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in /usr/local/lib/python3.12/dist-packages (from jupyterlab->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (2.27.3)\n",
            "Requirement already satisfied: notebook-shim>=0.2 in /usr/local/lib/python3.12/dist-packages (from jupyterlab->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (0.2.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (1.20.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from bleach[css]!=5.0.0->nbconvert->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (1.4.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.25.0->jupyterlab->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (0.16.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (0.8.4)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (0.4)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.12/dist-packages (from jupyter-core>=4.6.1->notebook->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (4.3.8)\n",
            "Requirement already satisfied: jupyter-events>=0.11.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (0.12.0)\n",
            "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (0.5.3)\n",
            "Requirement already satisfied: overrides>=5.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (7.7.0)\n",
            "Requirement already satisfied: websocket-client>=1.7 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (1.8.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.12/dist-packages (from argon2-cffi->notebook->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (25.1.0)\n",
            "Requirement already satisfied: babel>=2.10 in /usr/local/lib/python3.12/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (2.17.0)\n",
            "Requirement already satisfied: json5>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (0.12.1)\n",
            "Requirement already satisfied: jsonschema>=4.18.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (4.25.0)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.12/dist-packages (from nbformat->notebook->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (2.21.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (0.2.13)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.1->transformers[torch]>=4.38.0->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (1.3.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->nbconvert->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (2.7)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.25.0->jupyterlab->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (1.3.1)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (0.27.0)\n",
            "Requirement already satisfied: python-json-logger>=2.0.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (3.3.0)\n",
            "Requirement already satisfied: rfc3339-validator in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (0.1.4)\n",
            "Requirement already satisfied: rfc3986-validator>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (0.1.1)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (2.22)\n",
            "Requirement already satisfied: fqdn in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (1.5.1)\n",
            "Requirement already satisfied: isoduration in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (20.11.0)\n",
            "Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (3.0.0)\n",
            "Requirement already satisfied: rfc3987-syntax>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (1.1.0)\n",
            "Requirement already satisfied: uri-template in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (1.3.0)\n",
            "Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (24.11.1)\n",
            "Requirement already satisfied: lark>=1.2.2 in /usr/local/lib/python3.12/dist-packages (from rfc3987-syntax>=1.1.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (1.2.2)\n",
            "Requirement already satisfied: arrow>=0.15.0 in /usr/local/lib/python3.12/dist-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (1.3.0)\n",
            "Requirement already satisfied: types-python-dateutil>=2.8.10 in /usr/local/lib/python3.12/dist-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22) (2.9.0.20250809)\n"
          ]
        }
      ],
      "source": [
        "# Install the tsfm library\n",
        "! pip install \"granite-tsfm[notebooks] @ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.22\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e12f0358-1b55-4f45-b1e0-57d2c3e5d904",
      "metadata": {
        "id": "e12f0358-1b55-4f45-b1e0-57d2c3e5d904"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGrDK172ZFR5",
        "outputId": "932255a8-9700-419a-aeb9-288f833f8ac0"
      },
      "id": "iGrDK172ZFR5",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "f63ae353-96df-4380-89f6-1e6cebf684fb",
      "metadata": {
        "id": "f63ae353-96df-4380-89f6-1e6cebf684fb"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import os\n",
        "import tempfile\n",
        "\n",
        "import pandas as pd\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import OneCycleLR\n",
        "from transformers import EarlyStoppingCallback, Trainer, TrainingArguments, set_seed\n",
        "from transformers.integrations import INTEGRATION_TO_CALLBACK\n",
        "\n",
        "from tsfm_public import TimeSeriesPreprocessor, TrackingCallback, count_parameters, get_datasets\n",
        "from tsfm_public.toolkit.get_model import get_model\n",
        "from tsfm_public.toolkit.lr_finder import optimal_lr_finder\n",
        "from tsfm_public.toolkit.visualization import plot_predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "894ac389-94e4-4956-8d09-6509d9d452e6",
      "metadata": {
        "id": "894ac389-94e4-4956-8d09-6509d9d452e6"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "\n",
        "\n",
        "# Suppress all warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "092f5fa8-7f21-46d5-8356-2f313276d345",
      "metadata": {
        "id": "092f5fa8-7f21-46d5-8356-2f313276d345"
      },
      "source": [
        "### Important arguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "a826c4f3-1c6c-4088-b6af-f430f45fd380",
      "metadata": {
        "id": "a826c4f3-1c6c-4088-b6af-f430f45fd380"
      },
      "outputs": [],
      "source": [
        "# Set seed for reproducibility\n",
        "SEED = 42\n",
        "set_seed(SEED)\n",
        "\n",
        "# TTM Model path. The default model path is Granite-R2. Below, you can choose other TTM releases.\n",
        "TTM_MODEL_PATH = \"ibm-granite/granite-timeseries-ttm-r2\"\n",
        "# TTM_MODEL_PATH = \"ibm-granite/granite-timeseries-ttm-r1\"\n",
        "# TTM_MODEL_PATH = \"ibm-research/ttm-research-r2\"\n",
        "\n",
        "# Context length, Or Length of the history.\n",
        "# Currently supported values are: 512/1024/1536 for Granite-TTM-R2 and Research-Use-TTM-R2, and 512/1024 for Granite-TTM-R1\n",
        "CONTEXT_LENGTH = 512\n",
        "\n",
        "# Granite-TTM-R2 supports forecast length upto 720 and Granite-TTM-R1 supports forecast length upto 96\n",
        "PREDICTION_LENGTH = 96\n",
        "\n",
        "TARGET_DATASET = \"etth1\"\n",
        "dataset_path = \"https://raw.githubusercontent.com/zhouhaoyi/ETDataset/main/ETT-small/ETTh1.csv\"\n",
        "\n",
        "\n",
        "# Results dir\n",
        "OUT_DIR = \"ttm_finetuned_models/\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "60d594a0-0f2e-4a3a-b998-96d8d0e6b017",
      "metadata": {
        "id": "60d594a0-0f2e-4a3a-b998-96d8d0e6b017"
      },
      "source": [
        "# Data processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a56a0cca-1722-4a53-be74-4a13841693e7"
      },
      "source": [
        "# Dataset\n",
        "TARGET_DATASET = \"elec_pred\" # Changed dataset name\n",
        "dataset_path = \"/content/drive/MyDrive/dacon/elec_pred/train.csv\" # Updated dataset path\n",
        "test_dataset_path = \"/content/drive/MyDrive/dacon/elec_pred/test.csv\" # Added test dataset path\n",
        "submission_path = \"/content/drive/MyDrive/dacon/elec_pred/sample_submission.csv\" # Added submission file path\n",
        "\n",
        "timestamp_column = \"\"\n",
        "id_columns = [\"\"]  # mention the ids that uniquely identify a time-series.\n",
        "\n",
        "# Excluded '(hr)' and '(MJ/m2)' from target columns\n",
        "target_columns = [\"(C)\", \"(mm)\", \"(m/s)\", \"(%)\", \"(kWh)\"] # Updated target columns\n",
        "split_config = {\n",
        "    \"train\": [0, 1428], # 70% of 2040\n",
        "    \"valid\": [1428, 1734], # 15% of 2040\n",
        "    \"test\": [\n",
        "        1734,\n",
        "        2040, # 15% of 2040\n",
        "    ],\n",
        "}\n",
        "# Understanding the split config -- slides\n",
        "\n",
        "data = pd.read_csv(dataset_path)\n",
        "test_data = pd.read_csv(test_dataset_path) # Load test data\n",
        "submission_df = pd.read_csv(submission_path) # Load submission file\n",
        "\n",
        "data[timestamp_column] = pd.to_datetime(data[timestamp_column], format='%Y%m%d %H')\n",
        "test_data[timestamp_column] = pd.to_datetime(test_data[timestamp_column], format='%Y%m%d %H') # Convert timestamp in test data\n",
        "\n",
        "column_specifiers = {\n",
        "    \"timestamp_column\": timestamp_column,\n",
        "    \"id_columns\": id_columns,\n",
        "    \"target_columns\": target_columns,\n",
        "    \"control_columns\": [],\n",
        "}"
      ],
      "execution_count": 8,
      "outputs": [],
      "id": "a56a0cca-1722-4a53-be74-4a13841693e7"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8525cad6"
      },
      "source": [
        "display(data.head())"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "8525cad6"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1745d40",
        "outputId": "b29828d2-505e-484e-875d-2509ee7c7e06"
      },
      "source": [
        "for building_id, group in data.groupby(''):\n",
        "    print(f\" {building_id}:   = {len(group)}\")\n",
        "\n",
        "print(f\"\\n split_config: {split_config}\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1:   = 2040\n",
            " 2:   = 2040\n",
            " 3:   = 2040\n",
            " 4:   = 2040\n",
            " 5:   = 2040\n",
            " 6:   = 2040\n",
            " 7:   = 2040\n",
            " 8:   = 2040\n",
            " 9:   = 2040\n",
            " 10:   = 2040\n",
            " 11:   = 2040\n",
            " 12:   = 2040\n",
            " 13:   = 2040\n",
            " 14:   = 2040\n",
            " 15:   = 2040\n",
            " 16:   = 2040\n",
            " 17:   = 2040\n",
            " 18:   = 2040\n",
            " 19:   = 2040\n",
            " 20:   = 2040\n",
            " 21:   = 2040\n",
            " 22:   = 2040\n",
            " 23:   = 2040\n",
            " 24:   = 2040\n",
            " 25:   = 2040\n",
            " 26:   = 2040\n",
            " 27:   = 2040\n",
            " 28:   = 2040\n",
            " 29:   = 2040\n",
            " 30:   = 2040\n",
            " 31:   = 2040\n",
            " 32:   = 2040\n",
            " 33:   = 2040\n",
            " 34:   = 2040\n",
            " 35:   = 2040\n",
            " 36:   = 2040\n",
            " 37:   = 2040\n",
            " 38:   = 2040\n",
            " 39:   = 2040\n",
            " 40:   = 2040\n",
            " 41:   = 2040\n",
            " 42:   = 2040\n",
            " 43:   = 2040\n",
            " 44:   = 2040\n",
            " 45:   = 2040\n",
            " 46:   = 2040\n",
            " 47:   = 2040\n",
            " 48:   = 2040\n",
            " 49:   = 2040\n",
            " 50:   = 2040\n",
            " 51:   = 2040\n",
            " 52:   = 2040\n",
            " 53:   = 2040\n",
            " 54:   = 2040\n",
            " 55:   = 2040\n",
            " 56:   = 2040\n",
            " 57:   = 2040\n",
            " 58:   = 2040\n",
            " 59:   = 2040\n",
            " 60:   = 2040\n",
            " 61:   = 2040\n",
            " 62:   = 2040\n",
            " 63:   = 2040\n",
            " 64:   = 2040\n",
            " 65:   = 2040\n",
            " 66:   = 2040\n",
            " 67:   = 2040\n",
            " 68:   = 2040\n",
            " 69:   = 2040\n",
            " 70:   = 2040\n",
            " 71:   = 2040\n",
            " 72:   = 2040\n",
            " 73:   = 2040\n",
            " 74:   = 2040\n",
            " 75:   = 2040\n",
            " 76:   = 2040\n",
            " 77:   = 2040\n",
            " 78:   = 2040\n",
            " 79:   = 2040\n",
            " 80:   = 2040\n",
            " 81:   = 2040\n",
            " 82:   = 2040\n",
            " 83:   = 2040\n",
            " 84:   = 2040\n",
            " 85:   = 2040\n",
            " 86:   = 2040\n",
            " 87:   = 2040\n",
            " 88:   = 2040\n",
            " 89:   = 2040\n",
            " 90:   = 2040\n",
            " 91:   = 2040\n",
            " 92:   = 2040\n",
            " 93:   = 2040\n",
            " 94:   = 2040\n",
            " 95:   = 2040\n",
            " 96:   = 2040\n",
            " 97:   = 2040\n",
            " 98:   = 2040\n",
            " 99:   = 2040\n",
            " 100:   = 2040\n",
            "\n",
            " split_config: {'train': [0, 1428], 'valid': [1428, 1734], 'test': [1734, 2040]}\n"
          ]
        }
      ],
      "id": "c1745d40"
    },
    {
      "cell_type": "markdown",
      "id": "b9498749",
      "metadata": {
        "id": "b9498749"
      },
      "source": [
        "## Zero-shot evaluation method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "7935d099",
      "metadata": {
        "id": "7935d099"
      },
      "outputs": [],
      "source": [
        "def zeroshot_eval(dataset_name, batch_size, context_length=512, forecast_length=96):\n",
        "    # Get data\n",
        "\n",
        "    tsp = TimeSeriesPreprocessor(\n",
        "        **column_specifiers,\n",
        "        context_length=context_length,\n",
        "        prediction_length=forecast_length,\n",
        "        scaling=True,\n",
        "        encode_categorical=False,\n",
        "        scaler_type=\"standard\",\n",
        "    )\n",
        "\n",
        "    # Load model\n",
        "    zeroshot_model = get_model(\n",
        "        TTM_MODEL_PATH,\n",
        "        context_length=context_length,\n",
        "        prediction_length=forecast_length,\n",
        "        freq_prefix_tuning=False,\n",
        "        freq=None,\n",
        "        prefer_l1_loss=False,\n",
        "        prefer_longer_context=True,\n",
        "    )\n",
        "\n",
        "    dset_train, dset_valid, dset_test = get_datasets(\n",
        "        tsp, data, split_config, use_frequency_token=zeroshot_model.config.resolution_prefix_tuning\n",
        "    )\n",
        "\n",
        "    temp_dir = tempfile.mkdtemp()\n",
        "    # zeroshot_trainer\n",
        "    zeroshot_trainer = Trainer(\n",
        "        model=zeroshot_model,\n",
        "        args=TrainingArguments(\n",
        "            output_dir=temp_dir,\n",
        "            per_device_eval_batch_size=batch_size,\n",
        "            seed=SEED,\n",
        "            report_to=\"none\",\n",
        "        ),\n",
        "    )\n",
        "    # evaluate = zero-shot performance\n",
        "    print(\"+\" * 20, \"Test MSE zero-shot\", \"+\" * 20)\n",
        "    zeroshot_output = zeroshot_trainer.evaluate(dset_test)\n",
        "    print(zeroshot_output)\n",
        "\n",
        "    # get predictions\n",
        "\n",
        "    predictions_dict = zeroshot_trainer.predict(dset_test)\n",
        "\n",
        "    predictions_np = predictions_dict.predictions[0]\n",
        "\n",
        "    print(predictions_np.shape)\n",
        "\n",
        "    # get backbone embeddings (if needed for further analysis)\n",
        "\n",
        "    backbone_embedding = predictions_dict.predictions[1]\n",
        "\n",
        "    print(backbone_embedding.shape)\n",
        "\n",
        "    # plot\n",
        "    plot_predictions(\n",
        "        model=zeroshot_trainer.model,\n",
        "        dset=dset_test,\n",
        "        plot_dir=os.path.join(OUT_DIR, dataset_name),\n",
        "        plot_prefix=\"test_zeroshot\",\n",
        "        indices=[685, 118, 902, 1984, 894, 967, 304, 57, 265, 1015],\n",
        "        channel=0,\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f4b240d-69cb-4a57-8435-5c7e4de2fc4c",
      "metadata": {
        "id": "7f4b240d-69cb-4a57-8435-5c7e4de2fc4c"
      },
      "source": [
        "# Zeroshot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "298c54aa-4969-4be3-9d8b-e8b75dfc4ef0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 149
        },
        "id": "298c54aa-4969-4be3-9d8b-e8b75dfc4ef0",
        "outputId": "f61463f1-32da-42b6-ab7e-c4e0d36b67bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:/usr/local/lib/python3.12/dist-packages/tsfm_public/toolkit/get_model.py:Loading model from: ibm-granite/granite-timeseries-ttm-r2\n",
            "INFO:/usr/local/lib/python3.12/dist-packages/tsfm_public/toolkit/get_model.py:Model loaded successfully from ibm-granite/granite-timeseries-ttm-r2, revision = main.\n",
            "INFO:/usr/local/lib/python3.12/dist-packages/tsfm_public/toolkit/get_model.py:[TTM] context_length = 512, prediction_length = 96\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "++++++++++++++++++++ Test MSE zero-shot ++++++++++++++++++++\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='645' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [330/330 00:23]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.4398714303970337, 'eval_model_preparation_time': 0.0038, 'eval_runtime': 5.9904, 'eval_samples_per_second': 3522.325, 'eval_steps_per_second': 55.088}\n"
          ]
        }
      ],
      "source": [
        "zeroshot_eval(\n",
        "    dataset_name=TARGET_DATASET, context_length=CONTEXT_LENGTH, forecast_length=PREDICTION_LENGTH, batch_size=64\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import numpy as np # Import numpy\n",
        "import torch # Import torch to check for CUDA availability\n",
        "\n",
        "# Find the path to the best checkpoint directory\n",
        "# Assuming the fewshot_finetune_eval function was run and saved checkpoints in OUT_DIR/TARGET_DATASET/output\n",
        "output_dir = os.path.join(OUT_DIR, TARGET_DATASET, \"output\")\n",
        "list_of_checkpoints = glob.glob(f\"{output_dir}/checkpoint-*\")\n",
        "if not list_of_checkpoints:\n",
        "    raise FileNotFoundError(f\"No checkpoints found in {output_dir}. Please run the few-shot training cell first.\")\n",
        "latest_checkpoint = max(list_of_checkpoints, key=os.path.getctime)\n",
        "print(f\"Loading model from checkpoint: {latest_checkpoint}\")\n",
        "\n",
        "# Define the required prediction length for submission\n",
        "SUBMISSION_PREDICTION_LENGTH = 336\n",
        "\n",
        "# Create a TimeSeriesPreprocessor instance configured for the submission prediction length (336)\n",
        "tsp_submission = TimeSeriesPreprocessor(\n",
        "    **column_specifiers,\n",
        "    context_length=CONTEXT_LENGTH,\n",
        "    prediction_length=SUBMISSION_PREDICTION_LENGTH, # Set prediction length to 336 for submission\n",
        "    scaling=True,\n",
        "    encode_categorical=False,\n",
        "    scaler_type=\"standard\",\n",
        ")\n",
        "\n",
        "# Load the trained model from the checkpoint, configured for prediction_length 336\n",
        "# get_model should find a suitable TTM model that can predict 336 steps with CONTEXT_LENGTH context.\n",
        "# We need to load the weights from the fine-tuned checkpoint into this new model structure.\n",
        "# It's important that the TTM model architecture can handle predicting 336 steps even if trained on 96.\n",
        "# get_model should hopefully handle adapting the prediction head if needed.\n",
        "model_for_submission = get_model(\n",
        "    TTM_MODEL_PATH,\n",
        "    context_length=CONTEXT_LENGTH,\n",
        "    prediction_length=SUBMISSION_PREDICTION_LENGTH, # Set prediction length to 336\n",
        "    freq_prefix_tuning=False,\n",
        "    freq=None,\n",
        "    prefer_l1_loss=False,\n",
        "    prefer_longer_context=True,\n",
        "    # Use the same loss and quantile as trained if applicable\n",
        "    loss=\"pinball\", # Assuming pinball loss was used for training\n",
        "    quantile=0.5, # Assuming quantile 0.5 was used for training\n",
        ")\n",
        "\n",
        "# Load the state dict from the best checkpoint.\n",
        "# This assumes the model's state_dict is compatible with the new prediction_length.\n",
        "# If the prediction head's size changes, this might require careful handling or using a model factory that supports it.\n",
        "# Assuming from_pretrained handles this for TTM.\n",
        "model_for_submission.from_pretrained(latest_checkpoint)\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "model_for_submission.eval()\n",
        "if torch.cuda.is_available():\n",
        "    model_for_submission.to(\"cuda\")\n",
        "\n",
        "\n",
        "# Now we have the trained model. We need to generate predictions for the 336 hours for each building.\n",
        "# We will process each building's prediction separately.\n",
        "\n",
        "all_building_predictions = [] # To store predictions for all buildings\n",
        "\n",
        "# Iterate through unique building IDs in the original training data to maintain order\n",
        "for building_id in sorted(data[''].unique()):\n",
        "    print(f\"Generating predictions for Building {building_id}\")\n",
        "    # Get the last CONTEXT_LENGTH points from the training data for this building as context\n",
        "    building_train_data = data[data[''] == building_id]\n",
        "    context_data = building_train_data.tail(CONTEXT_LENGTH)\n",
        "\n",
        "    # Preprocess the context data using the submission preprocessor\n",
        "    # Create a temporary DataFrame for the context of this building\n",
        "    temp_context_df_single = context_data.copy()\n",
        "    temp_context_df_single.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    # Create a dataset for this single context window.\n",
        "    # We can use `get_datasets` by treating this as a 'train' split of length CONTEXT_LENGTH.\n",
        "    # We only need the 'train' dataset from this call.\n",
        "    # Ensure use_frequency_token matches the model's config.\n",
        "    single_context_dataset, _, _ = get_datasets(\n",
        "        tsp_submission, # Use the preprocessor configured for prediction_length 336\n",
        "        temp_context_df_single,\n",
        "        {\"train\": [0, CONTEXT_LENGTH]}, # Treat the single window as a 'train' split\n",
        "        fewshot_fraction=0,\n",
        "        fewshot_location=\"first\",\n",
        "        use_frequency_token=model_for_submission.config.resolution_prefix_tuning,\n",
        "    )\n",
        "\n",
        "    # Use a Trainer to make predictions on this single sample dataset\n",
        "    # Using a small batch size (1) for single sample prediction\n",
        "    trainer_single_prediction = Trainer(\n",
        "        model=model_for_submission,\n",
        "        args=TrainingArguments(\n",
        "            output_dir=os.path.join(OUT_DIR, \"prediction_temp_single\"), # Temporary output dir\n",
        "            per_device_eval_batch_size=1, # Predict one sample at a time\n",
        "            seed=SEED,\n",
        "            report_to=\"none\",\n",
        "            dataloader_num_workers=0, # Set to 0 for Colab to avoid potential issues\n",
        "            use_cpu=True if not torch.cuda.is_available() else False, # Use CPU if GPU not available\n",
        "            # Disable logging and saving for this prediction-only trainer\n",
        "            logging_strategy=\"no\",\n",
        "            save_strategy=\"no\",\n",
        "        ),\n",
        "    )\n",
        "\n",
        "    # Make the prediction (336 hours)\n",
        "    # The predict method returns a PredictionOutput object\n",
        "    prediction_output_single = trainer_single_prediction.predict(single_context_dataset)\n",
        "    predictions_single = prediction_output_single.predictions[0] # Shape (1, 336, num_targets)\n",
        "\n",
        "    # Extract '' predictions for this building\n",
        "    # The target columns are [\"(C)\", \"(mm)\", \"(m/s)\", \"(%)\", \"(kWh)\"]\n",
        "    # '(kWh)' is at index 4\n",
        "    power_predictions_single_building = predictions_single[0, :, 4] # Shape (336,)\n",
        "\n",
        "    # Store the predictions for this building\n",
        "    all_building_predictions.append(power_predictions_single_building)\n",
        "\n",
        "# Concatenate predictions from all buildings\n",
        "all_building_predictions_np = np.concatenate(all_building_predictions) # Shape (100 * 336,) = (33600,)\n",
        "\n",
        "# Now, format these predictions into the submission file structure.\n",
        "# The submission_df was loaded earlier and has 'num_date_time' and 'answer' columns.\n",
        "# We need to fill the 'answer' column with the predictions.\n",
        "\n",
        "# Ensure the length of predictions matches the submission dataframe\n",
        "# The submission_df should have 100 buildings * 336 hours = 33600 rows\n",
        "if len(all_building_predictions_np) != len(submission_df):\n",
        "    raise ValueError(f\"Prediction length mismatch. Expected {len(submission_df)} predictions ({len(submission_df) // 100} hours per building), but got {len(all_building_predictions_np)} ({len(all_building_predictions_np) // 100} hours per building)\")\n",
        "\n",
        "\n",
        "# Assign the predictions to the 'answer' column of the submission dataframe\n",
        "submission_df['answer'] = all_building_predictions_np\n",
        "\n",
        "# Save the submission file\n",
        "submission_output_path = os.path.join(OUT_DIR, \"submission.csv\")\n",
        "submission_df.to_csv(submission_output_path, index=False)\n",
        "\n",
        "print(f\"Submission file saved to: {submission_output_path}\")\n",
        "print(\"Submission file head:\")\n",
        "display(submission_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "bafpan5G4r3W",
        "outputId": "f6733191-7fc7-4cd8-b163-835184a418d8"
      },
      "id": "bafpan5G4r3W",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "No checkpoints found in ttm_finetuned_models/elec_pred/output. Please run the few-shot training cell first.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1679708072.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mlist_of_checkpoints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{output_dir}/checkpoint-*\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlist_of_checkpoints\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"No checkpoints found in {output_dir}. Please run the few-shot training cell first.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mlatest_checkpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_of_checkpoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetctime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Loading model from checkpoint: {latest_checkpoint}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: No checkpoints found in ttm_finetuned_models/elec_pred/output. Please run the few-shot training cell first."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b79e3b8-b80a-48c4-9ee7-810e9ebdfcd2",
      "metadata": {
        "id": "3b79e3b8-b80a-48c4-9ee7-810e9ebdfcd2"
      },
      "source": [
        " ## Few-shot finetune and evaluation method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "078c945a-9da7-4729-a95d-43cd615d0934",
      "metadata": {
        "id": "078c945a-9da7-4729-a95d-43cd615d0934"
      },
      "outputs": [],
      "source": [
        "def fewshot_finetune_eval(\n",
        "    dataset_name,\n",
        "    batch_size,\n",
        "    learning_rate=None,\n",
        "    context_length=512,\n",
        "    forecast_length=96,\n",
        "    fewshot_percent=5,\n",
        "    freeze_backbone=True,\n",
        "    num_epochs=50,\n",
        "    save_dir=OUT_DIR,\n",
        "    loss=\"mse\",\n",
        "    quantile=0.5,\n",
        "):\n",
        "    out_dir = os.path.join(save_dir, dataset_name)\n",
        "\n",
        "    print(\"-\" * 20, f\"Running few-shot {fewshot_percent}%\", \"-\" * 20)\n",
        "\n",
        "    # Data prep: Get dataset\n",
        "\n",
        "    tsp = TimeSeriesPreprocessor(\n",
        "        **column_specifiers,\n",
        "        context_length=context_length,\n",
        "        prediction_length=forecast_length,\n",
        "        scaling=True,\n",
        "        encode_categorical=False,\n",
        "        scaler_type=\"standard\",\n",
        "    )\n",
        "\n",
        "    # change head dropout to 0.7 for ett datasets\n",
        "    if \"ett\" in dataset_name:\n",
        "        finetune_forecast_model = get_model(\n",
        "            TTM_MODEL_PATH,\n",
        "            context_length=context_length,\n",
        "            prediction_length=forecast_length,\n",
        "            freq_prefix_tuning=False,\n",
        "            freq=None,\n",
        "            prefer_l1_loss=False,\n",
        "            prefer_longer_context=True,\n",
        "            # Can also provide TTM Config args\n",
        "            head_dropout=0.7,\n",
        "            loss=loss,\n",
        "            quantile=quantile,\n",
        "        )\n",
        "    else:\n",
        "        finetune_forecast_model = get_model(\n",
        "            TTM_MODEL_PATH,\n",
        "            context_length=context_length,\n",
        "            prediction_length=forecast_length,\n",
        "            freq_prefix_tuning=False,\n",
        "            freq=None,\n",
        "            prefer_l1_loss=False,\n",
        "            prefer_longer_context=True,\n",
        "            # Can also provide TTM Config args\n",
        "            loss=loss,\n",
        "            quantile=quantile,\n",
        "        )\n",
        "\n",
        "    # Use train.csv for train and valid, test.csv for test\n",
        "    dset_train, dset_val, _ = get_datasets(\n",
        "        tsp, data, {\"train\": split_config[\"train\"], \"valid\": split_config[\"valid\"]}, fewshot_fraction=fewshot_percent / 100, fewshot_location=\"first\", use_frequency_token=finetune_forecast_model.config.resolution_prefix_tuning,\n",
        "    )\n",
        "    dset_test, _, _ = get_datasets(\n",
        "        tsp, test_data, {\"test\": [0, len(test_data)]}, fewshot_fraction=0, fewshot_location=\"first\", use_frequency_token=finetune_forecast_model.config.resolution_prefix_tuning # Use test_data for test set, no few-shot on test\n",
        "    )\n",
        "\n",
        "\n",
        "    if freeze_backbone:\n",
        "        print(\n",
        "            \"Number of params before freezing backbone\",\n",
        "            count_parameters(finetune_forecast_model),\n",
        "        )\n",
        "\n",
        "        # Freeze the backbone of the model\n",
        "        for param in finetune_forecast_model.backbone.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        # Count params\n",
        "        print(\n",
        "            \"Number of params after freezing the backbone\",\n",
        "            count_parameters(finetune_forecast_model),\n",
        "        )\n",
        "\n",
        "    # Find optimal learning rate\n",
        "    # Use with caution: Set it manually if the suggested learning rate is not suitable\n",
        "    if learning_rate is None:\n",
        "        learning_rate, finetune_forecast_model = optimal_lr_finder(\n",
        "            finetune_forecast_model,\n",
        "            dset_train,\n",
        "            batch_size=batch_size,\n",
        "        )\n",
        "        print(\"OPTIMAL SUGGESTED LEARNING RATE =\", learning_rate)\n",
        "\n",
        "    print(f\"Using learning rate = {learning_rate}\")\n",
        "    finetune_forecast_args = TrainingArguments(\n",
        "        output_dir=os.path.join(out_dir, \"output\"),\n",
        "        overwrite_output_dir=True,\n",
        "        learning_rate=learning_rate,\n",
        "        num_train_epochs=num_epochs,\n",
        "        do_eval=True,\n",
        "        eval_strategy=\"epoch\",\n",
        "        per_device_train_batch_size=batch_size,\n",
        "        per_device_eval_batch_size=batch_size,\n",
        "        dataloader_num_workers=8,\n",
        "        report_to=\"none\",\n",
        "        save_strategy=\"epoch\",\n",
        "        logging_strategy=\"epoch\",\n",
        "        save_total_limit=1,\n",
        "        logging_dir=os.path.join(out_dir, \"logs\"),  # Make sure to specify a logging directory\n",
        "        load_best_model_at_end=True,  # Load the best model when training ends\n",
        "        metric_for_best_model=\"eval_loss\",  # Metric to monitor for early stopping\n",
        "        greater_is_better=False,  # For loss\n",
        "        seed=SEED,\n",
        "    )\n",
        "\n",
        "    # Create the early stopping callback\n",
        "    early_stopping_callback = EarlyStoppingCallback(\n",
        "        early_stopping_patience=10,  # Number of epochs with no improvement after which to stop\n",
        "        early_stopping_threshold=1e-5,  # Minimum improvement required to consider as improvement\n",
        "    )\n",
        "    tracking_callback = TrackingCallback()\n",
        "\n",
        "    # Optimizer and scheduler\n",
        "    optimizer = AdamW(finetune_forecast_model.parameters(), lr=learning_rate)\n",
        "    scheduler = OneCycleLR(\n",
        "        optimizer,\n",
        "        learning_rate,\n",
        "        epochs=num_epochs,\n",
        "        steps_per_epoch=math.ceil(len(dset_train) / (batch_size)),\n",
        "    )\n",
        "\n",
        "    finetune_forecast_trainer = Trainer(\n",
        "        model=finetune_forecast_model,\n",
        "        args=finetune_forecast_args,\n",
        "        train_dataset=dset_train,\n",
        "        eval_dataset=dset_val,\n",
        "        callbacks=[early_stopping_callback, tracking_callback],\n",
        "        optimizers=(optimizer, scheduler),\n",
        "    )\n",
        "    finetune_forecast_trainer.remove_callback(INTEGRATION_TO_CALLBACK[\"codecarbon\"])\n",
        "\n",
        "    # Fine tune\n",
        "    finetune_forecast_trainer.train()\n",
        "\n",
        "    # Evaluation\n",
        "    print(\"+\" * 20, f\"Test MSE after few-shot {fewshot_percent}% fine-tuning\", \"+\" * 20)\n",
        "\n",
        "    finetune_forecast_trainer.model.loss = \"mse\"  # fixing metric to mse for evaluation\n",
        "\n",
        "    fewshot_output = finetune_forecast_trainer.evaluate(dset_test)\n",
        "    print(fewshot_output)\n",
        "    print(\"+\" * 60)\n",
        "\n",
        "    # get predictions\n",
        "\n",
        "    predictions_dict = finetune_forecast_trainer.predict(dset_test)\n",
        "\n",
        "    predictions_np = predictions_dict.predictions[0]\n",
        "\n",
        "    print(predictions_np.shape)\n",
        "\n",
        "    # get backbone embeddings (if needed for further analysis)\n",
        "\n",
        "    backbone_embedding = predictions_dict.predictions[1]\n",
        "\n",
        "    print(backbone_embedding.shape)\n",
        "\n",
        "    # plot\n",
        "    plot_predictions(\n",
        "        model=finetune_forecast_trainer.model,\n",
        "        dset=dset_test,\n",
        "        plot_dir=os.path.join(OUT_DIR, dataset_name),\n",
        "        plot_prefix=\"test_fewshot\",\n",
        "        indices=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9], # Plot first 10 examples from the test set\n",
        "        channel=0,\n",
        "    )\n",
        "\n",
        "    return predictions_np"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e825cf28-f034-4a32-a729-0fe846ff2a26",
      "metadata": {
        "id": "e825cf28-f034-4a32-a729-0fe846ff2a26"
      },
      "source": [
        "### Few-shot 5%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "b145fead-50fb-4e3e-89fc-a0c238755e64",
      "metadata": {
        "id": "b145fead-50fb-4e3e-89fc-a0c238755e64",
        "outputId": "aa2d01a3-966e-44d9-9348-0f8393dc98ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:/usr/local/lib/python3.12/dist-packages/tsfm_public/toolkit/get_model.py:Loading model from: ibm-granite/granite-timeseries-ttm-r2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------- Running few-shot 5% --------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:/usr/local/lib/python3.12/dist-packages/tsfm_public/toolkit/get_model.py:Model loaded successfully from ibm-granite/granite-timeseries-ttm-r2, revision = main.\n",
            "INFO:/usr/local/lib/python3.12/dist-packages/tsfm_public/toolkit/get_model.py:[TTM] context_length = 512, prediction_length = 96\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'test'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-858626401.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m fewshot_finetune_eval(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mdataset_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTARGET_DATASET\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mcontext_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCONTEXT_LENGTH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mforecast_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPREDICTION_LENGTH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3171028176.py\u001b[0m in \u001b[0;36mfewshot_finetune_eval\u001b[0;34m(dataset_name, batch_size, learning_rate, context_length, forecast_length, fewshot_percent, freeze_backbone, num_epochs, save_dir, loss, quantile)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# Use train.csv for train and valid, test.csv for test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     dset_train, dset_val, _ = get_datasets(\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0mtsp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msplit_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"valid\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msplit_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"valid\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfewshot_fraction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfewshot_percent\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfewshot_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"first\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_frequency_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfinetune_forecast_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolution_prefix_tuning\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tsfm_public/toolkit/time_series_preprocessor.py\u001b[0m in \u001b[0;36mget_datasets\u001b[0;34m(ts_preprocessor, dataset, split_config, stride, fewshot_fraction, fewshot_location, as_univariate, use_frequency_token, enable_padding, seed, **dataset_kwargs)\u001b[0m\n\u001b[1;32m    917\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mts_preprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 919\u001b[0;31m     train_data, valid_data, test_data = prepare_data_splits(\n\u001b[0m\u001b[1;32m    920\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    921\u001b[0m         \u001b[0mid_columns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mts_preprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid_columns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tsfm_public/toolkit/time_series_preprocessor.py\u001b[0m in \u001b[0;36mprepare_data_splits\u001b[0;34m(data, id_columns, context_length, split_config)\u001b[0m\n\u001b[1;32m    839\u001b[0m     \"\"\"\n\u001b[1;32m    840\u001b[0m     \u001b[0;31m# get split_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m     \u001b[0msplit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_split_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m     \u001b[0;31m# split data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tsfm_public/toolkit/util.py\u001b[0m in \u001b[0;36mget_split_params\u001b[0;34m(split_config, context_length)\u001b[0m\n\u001b[1;32m   1078\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m\"valid\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msplit_config\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1079\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"test\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"valid\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1080\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msplit_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msplit_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1081\u001b[0m                 split_params[group] = {\n\u001b[1;32m   1082\u001b[0m                     \u001b[0;34m\"start_fraction\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msplit_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'test'"
          ]
        }
      ],
      "source": [
        "fewshot_finetune_eval(\n",
        "    dataset_name=TARGET_DATASET,\n",
        "    context_length=CONTEXT_LENGTH,\n",
        "    forecast_length=PREDICTION_LENGTH,\n",
        "    batch_size=64,\n",
        "    fewshot_percent=5,\n",
        "    learning_rate=0.001,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a69e561f-ff9f-4817-95f8-2721668fc2af",
      "metadata": {
        "id": "a69e561f-ff9f-4817-95f8-2721668fc2af"
      },
      "source": [
        "# Fewshot with quantile loss (We can use pinball loss to generate different quantiles as required)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5f92363-761e-41ea-bf48-d1c27b3376ff",
      "metadata": {
        "id": "d5f92363-761e-41ea-bf48-d1c27b3376ff"
      },
      "outputs": [],
      "source": [
        "fewshot_finetune_eval(\n",
        "    dataset_name=TARGET_DATASET,\n",
        "    context_length=CONTEXT_LENGTH,\n",
        "    forecast_length=PREDICTION_LENGTH,\n",
        "    batch_size=64,\n",
        "    fewshot_percent=5,\n",
        "    learning_rate=0.001,\n",
        "    loss=\"pinball\",\n",
        "    quantile=0.5,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cee2dcc1-bcb8-47ee-8ba7-ff3104159ed6",
      "metadata": {
        "id": "cee2dcc1-bcb8-47ee-8ba7-ff3104159ed6"
      },
      "source": [
        "## Example: TTM for other forecast horizon lengths and context lengths\n",
        "\n",
        "The minimum / maximum supported context length for the Granite-TTM-R2 models are 52 and 1536 respectively. Whereas the maximum supported prediction length for Granite-TTM-R2 is 720. (For other models, see the respective model cards)\n",
        "\n",
        "However, we can ask for a different context length or forecast length, and the `get_model()` utility will choose the closest possible TTM from the model suite. We have to make sure that the required context and prediction lengths are passed to the `TimeSeriesPreprocessor()` so that the data batches are generated correctly. In this notebook, this is handled in the `zeroshot_eval()` and `fewshot_finetune_eval()` functions."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31b58250-91a2-4db0-ab45-29b89f5afd0e",
      "metadata": {
        "id": "31b58250-91a2-4db0-ab45-29b89f5afd0e"
      },
      "source": [
        "### Zero-shot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4eff2e1-acfd-4c5b-8463-e084ba831cdf",
      "metadata": {
        "id": "b4eff2e1-acfd-4c5b-8463-e084ba831cdf"
      },
      "outputs": [],
      "source": [
        "zeroshot_eval(dataset_name=TARGET_DATASET, context_length=1024, forecast_length=48, batch_size=64)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00e56d63-5e87-41ae-8fe9-3b3cfd9d19f6",
      "metadata": {
        "id": "00e56d63-5e87-41ae-8fe9-3b3cfd9d19f6"
      },
      "source": [
        "### Few-shot 5%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b56cd24-bae6-4cc6-9a3c-52f965014eb0",
      "metadata": {
        "id": "4b56cd24-bae6-4cc6-9a3c-52f965014eb0"
      },
      "outputs": [],
      "source": [
        "fewshot_finetune_eval(\n",
        "    dataset_name=TARGET_DATASET,\n",
        "    context_length=1536,\n",
        "    forecast_length=48,\n",
        "    batch_size=64,\n",
        "    fewshot_percent=5,\n",
        "    learning_rate=None,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d39aba88-268d-4145-9ae9-e4db6df16b33",
      "metadata": {
        "id": "d39aba88-268d-4145-9ae9-e4db6df16b33"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "703e09dd"
      },
      "source": [
        "display(data.head())"
      ],
      "id": "703e09dd",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}